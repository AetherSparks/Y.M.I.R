# Y.M.I.R: Yielding Melodies for Internal Restoration ğŸµğŸ§   
*A Mood-Based AI Emotion Detection & Music Recommendation System*

![Y.M.I.R Banner](https://github.com/pallav110/DTI-AND-AI-PROJECT/blob/main/YMIR%20thumbnail.jpg?raw=true)
<!-- Replace with your actual image path once added -->

---

## ğŸ¥ **Watch the Demo Video**
[![Watch on YouTube](https://img.shields.io/badge/Watch%20Demo%20Video-Youtube-red?logo=youtube)](https://your-youtube-link.com)  
<!-- Replace with actual YouTube video link -->

---

## **Overview**  
**Y.M.I.R** is a cutting-edge AI-powered system that personalizes your music and wellness experience using emotional intelligence:

- **Multi-Channel Emotion Detection** â€“ Facial expression + text-based interaction ğŸ”  
- **Intelligent Music Matching** â€“ Personalized recommendations based on your current mood ğŸ·  
- **Wellness-First Experience** â€“ Chat support, daily motivation, and real-time emotional assistance ğŸ’¬ğŸ’¡  

---

## **Key Features**

| Feature | Description |
|---------|-------------|
| **ğŸŒ Multimodal Emotion Detection** | Combines DeepFace visual analysis with natural language processing for comprehensive emotional assessment |
| **ğŸ’¬ Interactive Emotion Chatbot** | Engages users in conversation to gather emotional context beyond facial expressions |
| **ğŸ“Š Emotion Fusion Algorithm** | Integrates visual and text-based emotional signals for enhanced accuracy |
| **ğŸ¶ Personalized Music Recommendations** | Content-based recommendation engine tailored to emotional states |
| **ğŸ”€ Real-Time Processing** | Continuous emotion monitoring and dynamic recommendation updates |
| **ğŸŒ Responsive Web Interface** | Flask-powered application accessible across devices |

---

## **Technical Architecture**

### ğŸ“ Project Structure
```
Y.M.I.R/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ therapeutic_music_enriched.csv
â”‚   â”œâ”€â”€ Y.M.I.R. original dataset.csv
â”‚   â””â”€â”€ imagesofdataset/
â”‚       â”œâ”€â”€ Figure_1.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ fer1.py
â”‚   â”œâ”€â”€ modules.py
â”‚   â”œâ”€â”€ recommend.py
â”‚   â””â”€â”€ train_music_recommendation.py
â”œâ”€â”€ static/
â”‚   â””â”€â”€ styles.css
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ about.html
â”‚   â”œâ”€â”€ contact.html
â”œâ”€â”€ Website-Images/
â”‚   â”œâ”€â”€ Homepage.jpg
â”‚   â””â”€â”€ ...
```

---

## ğŸš€ **Installation Guide**

### Prerequisites
- Python 3.8+
- Webcam access
- Internet connection

### Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/Y.M.I.R.git
   cd Y.M.I.R
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Launch the application**
   ```bash
   python app.py
   ```

5. **Access the interface**
   Open your browser at `http://127.0.0.1:5000/` and grant webcam permissions.

---

## ğŸ§  **How It Works**

### The Y.M.I.R Emotional Pipeline

1. **Emotion Capture**  
   - Facial recognition using webcam (DeepFace)  
   - Chatbot-based emotional interpretation (NLP)

2. **Signal Fusion**  
   - Combined analysis for deeper mood recognition

3. **Music Matching**  
   - Emotion-aware recommendation engine suggests therapeutic or uplifting tracks

4. **Continuous Support**  
   - Recommendations evolve with your emotional state

---

## ğŸ› ï¸ **Development Roadmap**

### âœ… Current Progress
- Emotion detection system (visual & textual)
- Music recommendation engine
- Web UI prototype
- Dataset integration (YMIR & therapeutic music)

### ğŸ”§ In Progress
- Improved UI & camera control
- Favorites system & user personalization
- Advanced emotion-music mapping
- Button functionality & chatbot refinement

---

## ğŸ’¡ **Contributing**

Weâ€™d love your input!

1. Fork the repo  
2. Create a branch (`git checkout -b feature/awesome-idea`)  
3. Commit changes (`git commit -m 'Add cool stuff'`)  
4. Push and submit a Pull Request

---

## ğŸ‘¨â€ğŸ’» **Team**

- **Abhiraj Ghose** â€“ E23CSEU0014
- [Abhiraj's GitHub Profile](https://github.com/AetherSparks) 
- **Pallav Sharma** â€“ E23CSEU0022  
- [Pallav's GitHub Profile](https://github.com/pallav)

---

## ğŸ™Œ **Acknowledgments**

- [DeepFace](https://github.com/serengil/deepface) â€“ Facial emotion detection  
- OpenAI â€“ Natural Language Processing  
- Flask & Python Community  
- Contributors to the YMIR dataset  

---

## ğŸ“„ **License**

This project is licensed under the MIT License. See `LICENSE` for details.

---

âš ï¸ **Note:** Y.M.I.R is currently in beta. Expect ongoing changes and new features as development continues.

